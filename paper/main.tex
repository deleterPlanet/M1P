\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\usepackage{hyperref, xcolor}
\usepackage[warn]{mathtext}
\usepackage{subcaption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{comment}

\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}



\title{Оптимизация количества деревьев в ансамбле градиентного бустинга с использованием стратегий выбора агрегирующих функций}

\author{ Якушевич Антон Сергеевич \\
	ВМК \\
	МГУ \\
	Москва \\
	\texttt{s02220301@gse.cs.msu.ru} \\
    \And
    Сенько Олег Валентинович \\
    ВМК \\
	МГУ \\
	Москва \\
	\texttt{senkoov@mail.ru} \\
}

\date{}

\renewcommand{\shorttitle}{M1P}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={Оптимизация количества деревьев в ансамбле градиентного бустинга с использованием стратегий выбора агрегирующих функций},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={Якушевич Антон Сергеевич},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
	В работе исследуется задача оптимизации ансамблей градиентного бустинга за счёт выбора обобщённой агрегирующей функции. Исследование проводится для уменьшения количества деревьев в ансамбле с целью повышения интерпретируемости модели при сохранении её прогностической точности. Для этого предлагается использовать усечённое разложение агрегирующей функции в ряд Тейлора и оптимизировать её коэффициенты с помощью градиентного спуска, что позволяет адаптивно настраивать структуру ансамбля и улучшать баланс между точностью и интерпретируемостью. Экспериментальные результаты показывают, что оптимизация коэффициентов ряда Тейлора приводит к уменьшению числа деревьев без потери качества, а в ряде случаев даже к улучшению точности
\end{abstract}


\keywords{First keyword \and Second keyword \and More}

\section{Введение}
% Зачем это надо
Градиентный бустинг остаётся одним из наиболее эффективных методов машинного обучения, применяемых в задачах регрессии и классификации. Однако высокая точность ансамбля достигается ценой увеличения числа деревьев, что усложняет интерпретацию модели и приводит к увеличению вычислительных затрат. Поэтому важной задачей является разработка подходов, позволяющих уменьшить размер ансамбля без ухудшения качества прогнозов.

% Как это решать (краткий обзор литературы)
Одним из направлений снижения сложности ансамблей является модификация агрегирующей функции. Наиболее простой подход заключается во введении весов для отдельных деревьев, которые подбираются либо вручную, либо оптимизируются на валидационных данных \citep{domke2012generic}. Более сложные методы рассматривают автоматическую настройку весов или коэффициентов, что позволяет повысить адаптивность ансамбля \citep{franceschi2017forward}. Другая линия исследований связана с использованием мета-моделей для агрегирования, таких как нейронные сети, которые применяются для того, чтобы обучаться более сложным функциям взвешивания базовых предсказаний \citep{differentiable2022hyperopt}. Подобные подходы расширяют пространство возможных агрегирующих функций и потенциально позволяют достичь более высокой точности. В смежных направлениях рассматривались и дифференцируемые методы оптимизации гиперпараметров \citep{maclaurin2015gradient, lorraine2019optimizing, shaban2019truncated}, где подбираются параметры регуляризации и обучения, что демонстрирует применимость автоматического дифференцирования к задачам настройки сложных моделей.

% Какие проблемы у решений
Несмотря на успехи, существующие подходы имеют ряд ограничений. Во-первых, во многих исследованиях агрегирующая функция задаётся заранее, как простое суммирование или линейная комбинация, что снижает адаптивность ансамбля \citep{domke2012generic}. Во-вторых, даже в случаях, когда веса подбираются автоматически, процесс оптимизации часто является дорогостоящим и требует перебора гиперпараметров или применения эвристик \citep{franceschi2017forward}. В-третьих, подходы, где агрегирующая функция параметризуется нейронной сетью \citep{differentiable2022hyperopt}, сталкиваются с ограничением: обучение функции проводится поверх уже зафиксированного набора деревьев, что не позволяет агрегирующей функции влиять на сам процесс построения ансамбля. Это делает такие методы менее гибкими и усложняет их использование на практике.

% Предлагаемое решение
В данной работе агрегирующая функция ансамбля представляется в виде усечённого разложения в ряд Тейлора, где коэффициенты ряда рассматриваются как параметры, подлежащие обучению. Для оптимизации этих коэффициентов используется следующая идея. Сначала строится оператор, который принимает на вход набор коэффициентов, затем обучает ансамбль деревьев с фиксированными гиперпараметрами, и, наконец, вычисляет значение функции потерь на валидационных данных. Возвращаемое оператором значение служит целевой функцией для обновления коэффициентов. Таким образом, коэффициенты агрегирующей функции оптимизируются напрямую с помощью градиентного спуска. Благодаря этому достигается совместная настройка структуры ансамбля и параметров агрегирования, что даёт дополнительную гибкость по сравнению с фиксированными или отдельно обучаемыми функциями.

% Результаты и вклад
Предложенный метод открывает новый способ интеграции оптимизации агрегирующих функций в процесс обучения ансамблей. В отличие от подходов, где агрегирующая функция задаётся заранее или обучается постфактум, наша методика позволяет адаптивно корректировать её форму одновременно с построением деревьев. Экспериментальные результаты показывают, что оптимизация коэффициентов ряда Тейлора приводит к уменьшению числа деревьев без потери качества, а в ряде случаев даже к улучшению точности. Тем самым достигается более выгодный баланс между точностью, интерпретируемостью и вычислительной эффективностью. Вклад работы заключается в том, что она расширяет область применения методов оптимизации, показывая, что обучение агрегирующих функций может быть встроено непосредственно в процесс градиентного бустинга, а не рассматриваться как внешний этап.


\section{Литературный обзор}
Ансамблевые методы давно зарекомендовали себя как один из наиболее эффективных классов алгоритмов машинного обучения \citep{breiman1996bagging, freund1997adaboost}. Среди них особое место занимает градиентный бустинг \citep{friedman2001greedy}, который благодаря высокой точности и универсальности получил широкое распространение как в академических исследованиях, так и в индустриальных приложениях \citep{chen2016xgboost, ke2017lightgbm}. Однако рост числа деревьев в ансамбле приводит к ухудшению интерпретируемости и повышению вычислительных затрат, что стимулировало поиск методов сокращения сложности без потери качества.

Одним из направлений развития бустинга стали методы регуляризации и усечения ансамблей. Ряд работ показал эффективность ограничений на глубину деревьев и скорости обучения \citep{zhang2005boosting, buhlmann2007boosting}, а также введения различных форм регуляризации \citep{mason2000boosting, friedman2002stochastic}. Другой класс подходов связан с сокращением ансамбля путём отбора наиболее информативных моделей \citep{margineantu1997reduced, caruana2004ensemble}, что позволяет уменьшить число деревьев при минимальных потерях в точности.

Ключевым элементом ансамблевых методов является агрегирующая функция, которая объединяет предсказания отдельных базовых алгоритмов в итоговый результат. В классических вариантах бустинга используется простая сумма или усреднение выходов деревьев с фиксированными весами \citep{hastie2009elements}. Однако такая схема имеет ограниченную гибкость и не всегда позволяет учесть различный вклад деревьев в итоговую точность. Для повышения адаптивности были предложены методы взвешивания, где каждому дереву приписывается коэффициент, подбираемый либо с помощью оптимизации на валидационных данных, либо через регуляризацию \citep{domke2012generic, franceschi2017forward}. Подобные подходы позволяют усилить значимость наиболее полезных моделей и, наоборот, снизить влияние переобученных деревьев.

В смежных исследованиях развивались методы stacking, где агрегирующая функция задавалась в виде отдельной модели, обучаемой на предсказаниях базовых алгоритмов \citep{wolpert1992stacked, ting1999issues, maclin1999popular}. В простейшем случае это линейная или логистическая регрессия, а в более сложных вариантах — регуляризованные модели или мета-классификаторы, способные учитывать взаимосвязи между деревьями. Такие методы обеспечивали более богатое пространство комбинаций по сравнению с фиксированными весами, но усложняли интерпретацию и повышали риск переобучения.

Параллельно активно развивалось направление дифференцируемой оптимизации гиперпараметров. Ключевая идея была предложена в работах \citet{maclaurin2015gradient} и \citet{domke2012generic}, где рассматривалось дифференцирование процесса обучения для вычисления градиентов валидационной ошибки. Дальнейшие исследования сосредоточились на масштабировании этого подхода \citep{franceschi2017forward, lorraine2019optimizing, shaban2019truncated}, использовании неявного дифференцирования и аппроксимаций обратного Гессиана \citep{pedregosa2016hyperparameter}, а также применении автоматического дифференцирования в широком классе моделей \citep{baydin2018automatic}. Эти работы подтвердили возможность точной и вычислительно эффективной оптимизации параметров, выходящих за рамки традиционных методов перебора и байесовской оптимизации \citep{snoek2012practical, bergstra2011algorithms}.

Несмотря на прогресс, существующие методы имеют ограничения. Весовые и линейные комбинации деревьев не всегда обеспечивают достаточную гибкость, а нейросетевые агрегаторы обучаются поверх фиксированного ансамбля, не влияя на сам процесс построения деревьев. Дифференцируемые методы гипероптимизации сосредоточены преимущественно на настройке параметров обучения и регуляризации, а не на структурных характеристиках агрегирования. Эти ограничения формируют исследовательский разрыв, восполняемый настоящей работой, где агрегирующая функция представляется в виде усечённого разложения в ряд Тейлора, а её коэффициенты оптимизируются напрямую градиентным спуском в ходе построения ансамбля.


\section{Постановка задачи}
% Описание данных
\subsection{Данные}
В работе использовались наборы данных для задач регрессии различной природы, отличающиеся по размерности признакового пространства и объёму выборки:
$$
\mathscr{D} = \{ (x_i, y_i) \}_{i=1}^n
$$
где $x_i \in \mathbb{R}^d$ - вектор признаков, а $y_i \in \mathbb{R}$ - целевая переменная.

В экспериментах использовался пул из 9 наборов данных для тестирования моделей, а также расширенный пул из 64 задач регрессии, применявшихся для обучения мета-модели.  

% Отображение
\subsection{Обобщение градиентного бустинга}
Обобщим метод градиентного бустинга. Пусть задана последовательность функций $\{F_N\}_{N=1}^{+\infty}$, где $F_N: \mathbb{R}^N \to \mathbb{R}$. На $(N+1)$-ом шаге обучения вместо стандартной суммы $\sum_{i=1}^{N} T_i(x)$ будем использовать обобщённую функцию ансамбля $F_N\left(T_1(x), T_2(x), \dots, T_N(x)\right)$, где $\{T_i\}_{i=1}^N$ -- базовые модели (решающие деревья), обученные на предыдущих шагах.

Задача состоит в нахождении такой последовательности функций ${F_N}$, которая при фиксированном числе базовых моделей $N$ обеспечивала бы лучшее качество приближения целевой функции $f(x)$ (относительно заданной функции потерь $\mathscr{L}$) по сравнению с классическим градиентным бустингом, использующим сумму в качестве агрегирующей функции.

\subsection{Параметризация агрегирующей функции}
Зафиксируем число $N$ и рассмотрим функцию от $N$ переменных $F_N(T_1(x), T_2(x), \dots, T_N(x))$. Разложим её в ряд Тейлора в окрестности точки $(a_1, a_2, \dots ,a_N )$:
$$
F_N(T_1(x), T_2(x), \dots, T_N(x)) = \sum_{k=0}^{+\infty} \Bigg[ \overbrace{\sum_{k_1=0}\sum_{k_2=0}\dots\sum_{k_N=0}}^{k_1 + k_2 + \dots + k_N = k} \frac{1}{k_1!k_2!\dots k_N!}\frac{\partial^k F_N(a_1, a_2, \dots, a_N)}{\partial T_1^{k_1} \partial T_2^{k_2} \dots \partial T_N^{k_N}} \prod_{i=1}^N (T_i(x)-a_i)^{k_i}\Bigg]
$$

Тогда вместо классической линейной комбинации деревьев в решающем лесе предлагается использовать обобщённую функцию ансамбля, которая является усечённым вариантом ряда Тейлора:
$$
\widehat{F}_N(T_1(x), T_2(x), \dots, T_N(x)) = \sum_{k=1}^{M} \Bigg[ \overbrace{\sum_{k_1=0}\sum_{k_2=0}\dots\sum_{k_N=0}}^{k_1 + k_2 + \dots + k_N = k} b_{k_1, k_2, \dots, k_N} \prod_{i=1}^N (T_i(x)-a_i)^{k_i} \Bigg]
$$
где $M, \ b_{k_1, k_2, \dots, k_N}, \ a_i$ -- гиперпараметры

При этом выбор значений $b_{k_1, k_2, \dots, k_N} \ \text{и} \ a_i$ позволяет моделировать различные виды функций $F_N$ при $M \to +\infty$.

Если количество используемых переменных меньше общего числа $L < N$ (например при обучении $(L+1)$-го дерева), то функция принимает вид:
$$
\widehat{F}_L(T_1(x), T_2(x), \dots, T_L(x)) = \sum_{k=1}^{M} \Bigg[ \overbrace{\sum_{k_1=0}\sum_{k_2=0}\dots\sum_{k_L=0}}^{k_1 + k_2 + \dots + k_L = k} b_{k_1, k_2, \dots, k_L, 0, \dots, 0} \prod_{i=1}^L (T_i(x)-a_i)^{k_i} \Bigg]
$$

Здесь нулевые значения индексов $k_{L+1}, \dots , k_N$ соответствуют игнорированию лишних переменных. Таким образом, при добавлении нового алгоритма в ансамбль старые слагаемые линейной комбинации остаются неизменными, а новые слагаемые просто дополняют разложение. Такой подход обеспечивает стабильность модели и позволяет эффективно наращивать ансамбль без пересчета уже найденных коэффициентов.

Для упрощения вычислений и повышения устойчивости модели будем нормализовать целевую переменную с помощью z-нормализации. Тогда центр разложения можно выбрать равным нулю: $(a_1, a_2, \dots ,a_N ) = \overline{0}$, а в качестве $M$ взять небольшое число.

Везде далее для упрощения восприятия под $F_N$ будет подразумеваться $\widehat{F}_N$.

\subsection{Стратегии обучения нового алгоритма}
Введём обозначение $F_N(x) = \sum_{k=1}^{M} \overbrace{\sum_{k_1=0}\sum_{k_2=0}\dots\sum_{k_N=0}}^{k_1 + k_2 + \dots + k_N = k} b_{k_1, k_2, \dots, k_N} T_1^{k_1}(x) T_2^{k_2}(x) \dots T_N^{k_N}(x)$. Для повышения точности приближения при добавлении нового алгоритма $T_{N+1}(x)$ вводится параметр скорости обучения (learning rate), который вычисляется как $\alpha = \frac{\delta}{N^\theta}$, где $N$ -- порядковый номер добавляемого алгоритма в ансамбле, а $\delta$ и $\theta$ -- гиперпараметры. Выбор вектора, на котором будет обучаться новый алгоритм, может осуществляться по одной из трёх стратегий:
\begin{enumerate}
    \item \textbf{Нахождение точного корня}:
    
        При добавлении нового алгоритма $T_{N+1}(x)$ в ансамбль требуется, чтобы функция $F_{N+1}(x)$ аппроксимировала целевую переменную $y$ для каждого объекта $x$ из обучающей выборки (т.е. $F_{N+1}(x) \approx y$). Если подставить известные значения $T_1(x), T_2(x), \dots , T_N(x)$ в выражение для $F_{N+1}(x)$, то задача сводится к решению полиномиального уравнения степени $M$ относительно неизвестного $T_{N+1}(x)$. Для каждого объекта $x_i$ из обучающей выборки необходимо решить уравнение вида $\sum_{k=0}^M C_k(x_i) \cdot z_i^k = y_i$, где $C_k(x_i)$ -- функции, однозначно задаваемые $T_1(x_i), \dots, T_N(x_i)$, а $z_i$ представляет собой искомое значение $T_{N+1}(x_i)$. Однако данное уравнение не всегда имеет точное решение; в таких случаях в качестве $z_i$ выбирается точка, в которой полином принимает значение, минимальное по модулю.
        
        После нахождения значений $z_i$ для всех объектов обучается новый алгоритм $T_{N+1}$ на векторе $\alpha \cdot (z_1, z_2, \dots , z_N)$. Отметим, что первый алгоритм всегда обучается именно по этой стратегии.

    \item \textbf{Градиент}:
        
        Пусть имеется функция потерь $\mathscr{L}(y, F(x))$, тогда можно записать, что $\mathscr{L}(y, F_{N+1}(x)) = \mathscr{L}(y, F_{N}(x) + \sum_{k=1}^M C_k(x) T_{N+1}^k(x))$, где $C_k(x)$ -- функции, однозначно задаваемые $T_1(x), \dots, T_N(x)$. Разложим $\mathscr{L}$ в ряд Тейлора в точке $T_{N+1}(x) = 0$ (для удобства переименуем $T_{N+1}(x)$ в $z$):
        \begin{align*}
            \mathscr{L}(y, F_{N}(x) + \sum_{k=1}^M C_k(x) z^k) &= \mathscr{L}(y, F_{N}(x)) + z \cdot \frac{\partial\mathscr{L}(y, F_{N}(x) + \sum_{k=1}^M C_k(x) z^k)}{\partial z} \Bigg|_{z=0} = \\
            &= \mathscr{L}(y, F_{N}(x)) + z \cdot C_1(x) \cdot \frac{\partial\mathscr{L}(y, F)}{\partial F} \Bigg|_{F=F_N(x)} 
        \end{align*}
        где $C_1 = \sum_{k=1}^M \overbrace{\sum_{k_1=0}\sum_{k_2=0}\dots\sum_{k_N=0}}^{k_1 + k_2 + \dots + k_N = k-1} b_{k_1, k_2, \dots, k_N} T_1^{k_1}(x) T_2^{k_2}(x) \dots T_N^{k_N}(x)$

        Возвращаясь к $T_{N+1}$:
        \begin{align*}
            T_{N+1}(x_i) = arg\min_T \mathscr{L}(y_i, F_{N}(x_i) + \sum_{k=1}^M C_k(x_i) T^k(x_i)) = arg\min_T \left( T(x_i) \cdot C_1(x_i) \cdot \frac{\partial\mathscr{L}(y, F)}{\partial F} \Bigg|_{F=F_N(x_i)} \right) 
        \end{align*}
        Отсюда получаем выражение для нового алгоритма $T_{N+1}(x_i) = -\alpha \cdot C_1(x_i) \cdot \frac{\partial\mathscr{L}(y, F)}{\partial F} \Bigg|_{F=F_N(x_i)}$, где $\alpha \in (0, 1]$

        Пример для MSE: $\mathscr{L}(y, F) = \frac{1}{2} ( y - F(x))^2$

        $$
        \frac{\partial \mathscr{L}(y, F)}{\partial F} = F(x) - y \Rightarrow T_{N+1}(x_i) = \alpha \cdot C_1(x_i) \cdot (y_i - F_N(x_i))
        $$
\end{enumerate}

\subsection{Стратегия оптимизации коэффициентов аргрегирующей функции}
При фиксированном наборе данных $\mathscr{D}$ можно определить оператор $A_\mathscr{D} (b): \mathbb{R}^P \to \mathbb{R}$, который для заданного вектора коэффициентов $b$ обучает градиентный бустинг и возвращает значение функции потерь для полученной модели.

Допустим, что этот оператор обладает непрерывными частными производными во всех точках. В таком случае, для вычисления этих производных можно применить следующий подход:

$$
\frac{\partial A_\mathscr{D}}{\partial b_i}\Bigg|_{b=b_0}  \approx \frac{A_\mathscr{D}(b_0 + \epsilon \cdot e_i) - A_\mathscr{D}(b_0)}{\epsilon}
$$

где $e_i$ - это единичный вектор, направленный вдоль $i$-й координатной оси.

Таким образом, данный оператор может быть оптимизирован методом градиентного спуска:
$$
b_i^{k+1} = b_i^k - \alpha \cdot \frac{\partial A_\mathscr{D}}{\partial b_i}\Bigg|_{b=b^k}
$$

\subsection{Мета-модель}
Для ускорения подбора коэффициентов агрегирующей функции рассмотрим следующую нейронную сеть:

\begin{tikzpicture}[
    node distance=1.5cm and 1cm,
    layer/.style={rectangle, draw=black!50, fill=black!10, minimum width=2.2cm, minimum height=0.8cm, rounded corners=2pt, align=center},
    input/.style={layer, fill=blue!10},
    output/.style={layer, fill=green!10},
    operator/.style={rectangle, draw=red!50, fill=red!10, minimum width=2.5cm, minimum height=1cm, rounded corners=2pt, align=center},
    arrow/.style={-Stealth, thick}
]

    % --- Первый ряд ---
    \node[input] (input) {Вход \\ $\mathscr{D}$};
    \node[layer, right=of input] (proj) {Input \\ projection};
    \node[layer, right=of proj] (encoder) {Encoder \\ (ISAB ×4, SAB)};
    \node[layer, right=of encoder] (pma) {PMA};
    \node[layer, right=of pma] (mlp) {MLP \\ + Residuals};

    % --- Второй ряд ---
    \node[output, below=1.2cm of mlp] (output) {Выход};
    \node[operator, left=of output] (operator) {$A_{\mathscr{D}}(b)$};
    \node[left=of operator] (loss) {(1) $\mathscr{L}$};
    \node[right=of output] (sec_out) {$b$ (2)}

    % --- Стрелки первого ряда ---
    \draw[arrow] (input) -- (proj);
    \draw[arrow] (proj) -- (encoder);
    \draw[arrow] (encoder) -- (pma);
    \draw[arrow] (pma) -- (mlp);

    % --- Переход вниз и второй ряд ---
    \draw[arrow] (mlp.south) -- ++(0,-0.6) -| (output.north);
    \draw[arrow] (output) -- (operator);
    \draw[arrow] (output) -- (sec_out);
    \draw[arrow] (operator) -- (loss);

\end{tikzpicture}


\begin{comment}
\begin{tikzpicture}[
    node distance=1.5cm and 1cm,
    layer/.style={rectangle, draw=black!50, fill=black!10, minimum width=1.5cm, minimum height=0.8cm},
    input/.style={layer, fill=blue!10},
    output/.style={layer, fill=green!10, minimum width=2cm},
    operator/.style={rectangle, draw=red!50, fill=red!10, minimum width=2cm, minimum height=1cm},
    arrow/.style={-Stealth, thick}
]

    % Входной слой
    \node[input] (input) {Вход};
    \draw[arrow] ([xshift=-1cm]input.west) -- (input.west) node[midway, above] {$\mathscr{D}$};
    
    % Первый скрытый слой
    \node[layer, right=of input] (hidden1) {FC};
    \draw[arrow] (input) -- (hidden1);
    
    % Второй скрытый слой
    %\node[layer, right=of hidden1] (hidden2) {FC};
    %\draw[arrow] (hidden1) -- (hidden2);
    
    % Троеточие
    \node[right=of hidden1] (dots) {$\dots$};
    \draw[arrow] (hidden1) -- (dots);

    % Предпоследний слой
    \node[layer, right=of dots] (hidden2) {FC};
    \draw[arrow] (dots) -- (hidden2);
    
    % Выходной слой
    \node[output, right=of hidden2] (output) {Выход};
    \draw[arrow] (hidden2) -- (output);
    
    % Стрелка с b вниз
    \draw[arrow] (output.south) -- ++(0,-1) node[midway, right] {$b$} node[midway, left] {(2)};

    % Оператор A_D(b) справа
    \node[operator, right=of output] (operator) {$A_{\mathscr{D}}(b)$};
    \draw[arrow] (output.east) -- (operator.west) node[midway, above] {$b$};
    
    % Лосс
    \node[right=of operator] (loss) {$\mathscr{L}$ (1)};
    \draw[arrow] (operator.east) -- (loss.west);
\end{tikzpicture}\
\end{comment}
Процесс обучения модели осуществляется по траектории (1) с использованием алгоритма обратного распространения ошибки (метод вычисления градиента через оператор $A_{\mathscr{D}}(b)$ был представлен ранее). После завершения обучения модель функционирует по траектории (2) для генерации коэффициентов $b$, которые в дальнейшем используются для обучения градиентного бустинга.

% Внешний критерий качества
\subsection{Внешний критерий качества}
В процессе обучения в качестве функции потерь используется \textbf{MSE}:
$$
\mathscr{L}(y, F(x)) = \frac{1}{2}(y - F(x))^2.
$$

Минимизация данной функции потерь осуществляется на обучающей выборке и определяет процесс построения ансамбля.

Для внешней оценки качества модели на тестовой выборке ($\mathscr{D}$) используется \textbf{RMSE}:
$$
Q = \sqrt{\sum_{(x, y) \in \mathscr{D}} (y - F_N(x))^2}.
$$

Цель оптимизации заключается в снижении значения функции потерь $\mathscr{L}$ на этапе обучения, что, в свою очередь, позволяет достичь меньших значений внешнего критерия $Q$ при том же числе базовых моделей.

Снижение внутреннего лосса означает, что ансамбль достигает заданного уровня точности при меньшем числе деревьев, сохраняя качество предсказаний на уровне стандартного градиентного бустинга.

Иными словами, если для классического градиентного бустинга с фиксированным числом деревьев $N_0$ достигается ошибка $Q_0$, то предлагаемая модель позволяет получить $Q < Q_0$ при том же $N_0$. Это, в свою очередь, даёт возможность уменьшить число деревьев до $N < N_0$, сохранив ошибку на уровне $Q \approx Q_0$.

% Оптимизационная задача
\subsection{Оптимизационная задача}
Оптимизация параметров $b = \{b_{k_1, \dots, k_N}\}$ осуществляется с помощью градиентного спуска с моментом:
$$
\begin{cases}
    v^{(k+1)} = \mu v^{(k)} - \eta \nabla_b A_\mathscr{D}(b^{(k)}), \\
    b^{(k+1)} = b^{(k)} + v^{(k+1)},
\end{cases}
$$
где $\eta > 0$ — шаг обучения, $\mu \in [0,1)$ — коэффициент момента, $v^{(k)}$ — накопленный импульс изменения параметров.

Обучение мета-модели направлено на минимизацию функционала
$$
\mathscr{J}(\phi) = A_{\mathscr{D}}(\Psi_{\phi}(\mathscr{D})),
$$
где $\Psi_{\phi}$ — нейронная сеть с параметрами $\phi$, формирующая вектор коэффициентов $b = \Psi_{\phi}(\mathscr{D})$, используемых при построении ансамбля.  
Оператор $A_{\mathscr{D}}(b)$ для фиксированной выборки $\mathscr{D}$ возвращает значение функции потерь, соответствующее обученному ансамблю с коэффициентами $b$.

Таким образом, задача оптимизации параметров мета-модели может быть записана в виде:
$$
\min_{\phi} \ \mathscr{J}(\phi) = \min_{\phi} \ A_{\mathscr{D}}(\Psi_{\phi}(\mathscr{D})).
$$

Минимизация функционала $\mathscr{J}(\phi)$ осуществляется с использованием адаптивного алгоритма \textbf{Adam}. Алгоритм обеспечивает устойчивую и быструю сходимость при оптимизации нейронных сетей, что особенно важно при вычислении производных через оператор $A_{\mathscr{D}}(b)$.

На практике оптимизация выполняется итеративно: для каждой задачи из множества $\{\mathscr{D}_i\}$ вычисляется значение функционала $\mathscr{J}(\phi)$, выполняется обратное распространение градиента и обновление параметров $\phi$ оптимизатором \textbf{Adam}.

\section{Эксперименты}

Для оценки эффективности предложенного подхода были проведены эксперименты на множестве тестовых задач различной размерности и сложности.

В качестве базовой модели использовался стандартный градиентный бустинг. Так как в существующей литературе отсутствуют работы, направленные на оптимизацию агрегирующей функции в градиентном бустинге, данный вариант служит естественной точкой сравнения.  

Кроме того, рассматривалась модификация \textbf{FGBReg} (Functional Gradient Boosting Regressor) — базовый вариант предлагаемой модели, в котором агрегирующая функция представлена в виде усечённого ряда Тейлора. При этом коэффициенты задаются по правилу $b_{k_1, \dots, k_N} = \frac{1}{\sum_{i=1}^N k_i}$. Данная версия служит контрольной, позволяя оценить влияние процедуры оптимизации коэффициентов на итоговое качество модели.

Для проверки эффективности оптимизации агрегирующей функции рассматривались две стратегии обучения коэффициентов $b$:

\begin{itemize}
    \item \textbf{FGBReg + GD.}  
    Для каждой задачи из тестового пула исходная выборка делится на две равные части. На первой половине данных вектор коэффициентов $b$ оптимизируется с помощью градиентного спуска, после чего на второй половине вычисляется тестовая ошибка с использованием кросс-валидации.

    \item \textbf{FGBReg + NN.}  
    Для ускорения и обобщения процесса подбора коэффициентов $b$ была обучена нейронная сеть, описанная ранее. Обучение мета-модели выполнялось на пуле из 64 различных задач. После завершения обучения качество модели оценивалось на тех же 9 тестовых наборах данных, что использовались в предыдущем эксперименте, по метрике\textbf{RMSE} с использованием кросс-валидации.
\end{itemize}

Результаты экспериментов приведены в Таблице \ref{tab:results}.  Для каждого набора данных указаны значения \textbf{RMSE} для стандартного градиентного бустинга (\textbf{GB}), предложенной модели с фиксированными коэффициентами (\textbf{FGBReg}), а также для вариантов с оптимизацией $b$ с помощью градиентного спуска (\textbf{FGBReg + GD}) и нейронной сети (\textbf{FGBReg + NN}). Во всех экспериментах число деревьев в ансамбле фиксировалось на уровне $N = 20$.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
    \hline
     Набор данных & GB              & FGBReg   & FGBReg + GD    & FGBReg + NN     \\
    \hline
    task1         & 93.69           & 95.72   & \textbf{86.78}  & 114.1           \\
    task6         & 123.8           & 119.7   & \textbf{107.4}  & 129.5           \\
    task7         & 8.424           & 8.380   & \textbf{8.366}  & 8.443           \\
    \hline
    task10        & \textbf{0.177}  & 0.178   & 0.233           & 0.193           \\
    task16        & 41.03           & 33.54   & 0000            & \textbf{28.93}  \\
    task18        & \textbf{68.85}  & 77.60   & 74.45           & 80.41           \\
    \hline
    task41        & 0.401           & 0.364   & 0.356           & \textbf{0.331}  \\
    task901       & \textbf{309.0}  & 361.7   & 367.1           & 686.1           \\
    task970       & \textbf{40688}  & 46121   & 0000            & 55999           \\
    \hline
\end{tabular}
\caption{Результаты экспериментов на тестовых наборах данных}
\label{tab:results}
\end{table}

Из таблицы видно, что оптимизация коэффициентов агрегирующей функции с помощью градиентного спуска в большинстве случаев приводит к снижению значения \textbf{RMSE} по сравнению с фиксированной моделью. Использование мета-модели позволяет достичь сравнимого или лучшего качества в ряде задач, при этом сильно ускоряя этап подбора вектора $b$.  

Таким образом, предложенные методы демонстрируют потенциал к уменьшению числа базовых моделей в ансамбле при сохранении или улучшении точности по сравнению со стандартным градиентным бустингом.

\section{Выводы}
В работе был предложен обобщённый подход к построению ансамблей на основе градиентного бустинга, в котором классическая сумма базовых моделей заменяется параметризованной агрегирующей функцией в виде усечённого разложения в ряд Тейлора. Такой подход позволяет гибко моделировать взаимодействие между базовыми алгоритмами и, как следствие, повышать качество аппроксимации при фиксированном числе деревьев в ансамбле.

Результаты экспериментов показали, что предложенный подход способен снижать значение ошибки \textbf{RMSE} по сравнению с классическим градиентным бустингом. Особенно заметное улучшение наблюдается для варианта с оптимизацией коэффициентов методом градиентного спуска, что подтверждает целесообразность замены фиксированных коэффициентов на адаптивные. Использование нейронной мета-модели также демонстрирует потенциал, однако требует дополнительной настройки архитектуры и процедуры обучения для повышения устойчивости результатов.

Таким образом, предложенная концепция функционального градиентного бустинга открывает перспективы для дальнейшего развития ансамблевых методов, в частности — в направлении автоматического выбора агрегирующих функций и переноса знаний между задачами.


\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}