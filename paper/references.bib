@article{breiman1996bagging,
  title={Bagging Predictors},
  author={Leo Breiman},
  journal={Machine Learning},
  year={1996}
}

@article{freund1997adaboost,
  title={A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
  author={Yoav Freund, Robert E. Schapire},
  journal={Journal of Computer and System Sciences},
  year={1997}
}

@article{friedman2001greedy,
  title={Greedy Function Approximation: A Gradient Boosting Machine},
  author={Jerome H. Friedman},
  journal={The Annals of Statistics},
  year={2001}
}

@article{chen2016xgboost,
  title={XGBoost: A Scalable Tree Boosting System},
  author={Tianqi Chen, Carlos Guestrin},
  journal={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year={2016}
}

@article{ke2017lightgbm,
  title={LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
  author={Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu},
  journal={Advances in Neural Information Processing Systems 30 (NIP 2017)},
  year={2017}
}

@article{zhang2005boosting,
  title={Boosting with early stopping: Convergence and consistency},
  author={Tong Zhang, Bin Yu},
  journal={The Annals of Statistics},
  year={2005}
}

@article{buhlmann2007boosting,
  title={Boosting Algorithms: Regularization, Prediction and Model Fitting},
  author={Peter B{\"u}hlmann, Torsten Hothorn},
  journal={Statistical Science},
  year={2007}
}

@article{mason2000boosting,
  title={Boosting Algorithms as Gradient Descent},
  author={Llew Mason, Jonathan Baxter, Peter Bartlett, Marcus Frean},
  journal={Advances in Neural Information Processing Systems 12},
  year={2000}
}

@article{friedman2002stochastic,
  title={Stochastic Gradient Boosting},
  author={Jerome H Friedman},
  journal={Computational Statistics \& Data Analysis},
  year={2002}
}

@article{margineantu1997reduced,
  title={Pruning Adaptive Boosting},
  author={Dragos D Margineantu, Thomas G Dietterich},
  journal={Proceedings of the 14th International Conference on Machine Learning (ICML)},
  year={1997}
}

@article{caruana2004ensemble,
  title={Ensemble Selection from Libraries of Models},
  author={Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, Alex Ksikes},
  journal={Proceedings of the 21st International Conference  (ICML 2004)},
  year={2004}
}

@book{hastie2009elements,
  title={The Elements of Statistical Learning: Data mining, Inference, and Prediction},
  author={Trevor Hastie, Robert Tibshirani, Jerome Friedman},
  year={2009},
  publisher={Springer}
}

@article{domke2012generic,
  title={Generic Methods for Optimization-Based Modeling},
  author={Justin Domke},
  journal={Journal of Machine Learning Research},
  year={2012}
}

@article{franceschi2017forward,
  title={Forward and Reverse Gradient-Based Hyperparameter Optimization},
  author={Luca Franceschi, Michele Donini, Paolo Frasconi, Massimiliano Pontil},
  journal={Proceedings of the 34th International Conference on Machine Learning (ICML)},
  year={2017}
}

@article{wolpert1992stacked,
  title={Stacked Generalization},
  author={David H Wolpert},
  journal={Neural Networks},
  year={1992}
}

@article{ting1999issues,
  title={Issues in Stacked Generalization},
  author={K. M. Ting, I. H. Witten},
  journal={Journal of Artificial Intelligence Research},
  year={1999}
}

@article{maclin1999popular,
  title={Popular Ensemble Methods: An Empirical Study},
  author={R. Maclin, D. Opitz},
  journal={Journal of Artificial Intelligence Research},
  year={1999}
}

@article{cortes2017adanet,
  title={AdaNet: Adaptive Structural Learning of Artificial Neural Networks},
  author={Corinna Cortes, Javier Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, Scott Yang},
  journal={Proceedings of the 34th International Conference on Machine Learning (ICML)},
  year={2017}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Jonathan Lorraine, Paul Vicol, David Duvenaud},
  journal={Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2019}
}

@article{shaban2019truncated,
  title={Truncated Back-propagation for Bilevel Optimization},
  author={Amirreza Shaban, Ching-An Cheng, Nolan Hatch, Byron Boots},
  journal={Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2019}
}

@article{maclaurin2015gradient,
  title={Gradient-based Hyperparameter Optimization through Reversible Learning},
  author={Dougal Maclaurin, David Duvenaud, Ryan P Adams},
  journal={Proceedings of the 32nd International Conference on Machine Learning (ICML)},
  year={2015}
}

@article{pedregosa2016hyperparameter,
  title={Hyperparameter optimization with approximate gradient},
  author={Fabian Pedregosa},
  journal={Proceedings of the 33rd International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{baydin2018automatic,
  title={Automatic differentiation in machine learning: A survey},
  author={Atilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, Jeffrey Mark Siskind},
  journal={Journal of Machine Learning Research},
  year={2018}
}

@article{snoek2012practical,
  title={Practical Bayesian Optimization of Machine Learning Algorithms},
  author={Jasper Snoek, Hugo Larochelle, Ryan P Adams},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2012}
}

@article{bergstra2011algorithms,
  title={Algorithms for Hyper-Parameter Optimization},
  author={James Bergstra, R Bardenet, Balázs Kégl, Y. Bengio},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2011}
}

@article{differentiable2022hyperopt,
  title={Differentiable Hyper-parameter Optimization},
  author={Anonymous},
  journal={ICLR 2022}, 
  year={2022}
}
